# Python+PyTorch模型代码导向学习计划

### 一、Python 核心巩固阶段（1-2 周）：聚焦模型代码必备能力



| 天数  | 学习内容（核心知识点）                                                                                                                           | 实战练习                                                                                             | 推荐资源                                                   |
| --- | ------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------ | ------------------------------------------------------ |
| 1-2 | 1. 函数进阶：默认参数、可变参数（\*args/\*kwargs）、匿名函数 lambda2. 类与面向对象：类定义、\_\_init\_\_方法、继承（模型代码中常用自定义层）                                            | 1. 写一个 “数据预处理函数”：输入 list/dict，输出标准化后的 numpy 数组2. 定义一个 “基础层类”：包含初始化权重、前向计算方法                      | 1. 菜鸟教程 - Python 函数 / 类2. 快速过《Python 编程：从入门到实践》第 8-9 章 |
| 3-4 | 1. numpy 核心：数组创建（np.array）、形状操作（reshape/transpose）、广播机制、常用计算（mean/std/sum）2. pandas 基础：读取 CSV（pd.read\_csv）、提取列（df \[]）、缺失值填充（fillna） | 1. 用 numpy 实现 “批量数据标准化”（输入 (100,28) 的数组，输出每个特征标准化后的数据）2. 用 pandas 读取 MNIST 数据集的标签文件，转换为 numpy 数组 | 1. numpy 官方快速入门（10 分钟教程）2. pandas 官方 Getting Started   |
| 5-7 | 1. 文件操作：读取 txt/csv（with open/pandas）、保存 numpy 数组（np.save）2. 常用工具：for 循环优化（enumerate）、条件判断（if-elif 在模型训练中控制流程）                         | 1. 写一个 “数据加载脚本”：读取文件夹下所有 CSV，合并为一个 numpy 数组并保存2. 用 enumerate 遍历批量数据，打印每个批次的索引和数据形状               | 1. Python 官方文件操作文档2. 实战代码参考 Kaggle 基础脚本                |

### 二、PyTorch 基础入门阶段（2-3 周）：掌握模型代码核心组件



| 天数    | 学习内容（核心知识点）                                                                                                                                                             | 实战练习                                                                                                                             | 推荐资源                                                                |
| ----- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------- |
| 1-3   | 1. 张量（Tensor）：创建（torch.tensor/torch.rand）、数据类型（float32）、设备（cpu/cuda）、与 numpy 转换（torch.from\_numpy/np.array）2. 张量操作：索引切片、形状变换（view/permute）、广播、梯度开启（requires\_grad=True） | 1. 用张量复现 numpy 的 “批量标准化”，对比两者结果2. 创建一个形状为 (32,1,28,28) 的张量（模拟 32 张 28x28 的灰度图），转移到 cuda（若有 GPU）                                  | 1. PyTorch 官方教程 - Tensors2. 李沐《动手学深度学习》PyTorch 版第 2 章               |
| 4-6   | 1. 自动求导：torch.autograd.backward、梯度清零（zero\_grad）2. 数据加载：Dataset 类（自定义数据集）、DataLoader（批量加载、打乱、并行）                                                                        | 1. 实现 “线性回归求导”：定义 y=2x+1，用张量计算损失（MSE）并反向求导2. 自定义 MNIST Dataset：读取本地图片和标签，返回 (img\_tensor, label)，用 DataLoader 加载（batch\_size=32） | 1. PyTorch 官方教程 - Autograd2. PyTorch 官方教程 - Data Loading            |
| 7-10  | 1. 模型构建：torch.nn 模块（Sequential、Linear、Conv2d、ReLU、Dropout）2. 模型定义：两种方式（Sequential 堆叠、自定义类继承 nn.Module）                                                                  | 1. 用 Sequential 构建 “2 层全连接网络”（输入 784→隐藏层 256→输出 10）2. 自定义 “简单 CNN 类”：包含 1 个卷积层（in=1,out=16）、1 个池化层、1 个全连接层                       | 1. PyTorch 官方教程 - Neural Networks2. 李沐《动手学深度学习》第 6 章                |
| 11-14 | 1. 训练流程：优化器（torch.optim.SGD/Adam）、损失函数（nn.CrossEntropyLoss）2. 训练循环：epoch 遍历、批次训练（forward→loss→backward→step）                                                            | 1. 完整训练 “全连接网络”：用 MNIST 数据集，写训练循环（10 个 epoch），打印每轮准确率2. 调整优化器参数（学习率从 0.01 改为 0.001），对比训练效果                                       | 1. PyTorch 官方教程 - Training a Classifier2. GitHub 开源 MNIST 训练代码（简化版） |

### 三、PyTorch 模型实战阶段（2-3 周）：对标 “看懂 + 编写” 目标



| 实战主题             | 学习内容                                                                                 | 代码任务                                                                    | 推荐参考                                                                           |
| ---------------- | ------------------------------------------------------------------------------------ | ----------------------------------------------------------------------- | ------------------------------------------------------------------------------ |
| 1. 全连接网络（2 天）    | 1. 模型调参：学习率、批次大小、隐藏层数量的影响2. 常用技巧：早停（Early Stopping）、模型保存 / 加载（torch.save/torch.load） | 1. 基于之前的 MNIST 代码，添加 “模型保存”（保存准确率最高的模型）2. 实现早停：连续 3 轮准确率不提升则停止训练        | 1. PyTorch 官方模型保存文档2. Kaggle MNIST 调参笔记                                        |
| 2. CNN 模型（3-4 天） | 1. CNN 核心：卷积层（感受野）、池化层（下采样）、批归一化（nn.BatchNorm2d）2. 经典结构：LeNet-5 简化版（适配 MNIST）        | 1. 复现 LeNet-5：调整卷积核数量（6→16）、全连接层维度2. 对比 CNN 与全连接网络的训练准确率和收敛速度           | 1. LeNet-5 原始论文（简化解读）2. 李沐《动手学深度学习》第 7 章                                       |
| 3. 迁移学习（2-3 天）   | 1. 预训练模型：加载 torchvision.models（ResNet18）2. 微调技巧：冻结特征层、修改全连接层适配新任务                    | 1. 用 ResNet18 做 “猫狗分类”（简化版：用 100 张猫 / 狗图片）2. 分别尝试 “冻结特征层” 和 “全量微调”，对比效果 | 1. PyTorch 官方迁移学习教程2. torchvision.models 文档                                    |
| 4. 代码解读训练（2-3 天） | 1. 开源代码结构：数据加载、模型定义、训练循环、日志打印的常见写法2. 关键注释：学会标注模型层作用、训练步骤含义                           | 1. 找 1 篇简单的 PyTorch 开源论文代码（如小数据集分类），逐行添加注释2. 基于注释，修改模型结构（如增加一个卷积层）并重新训练 | 1. GitHub 搜索 “PyTorch simple classification”2. 论文附录代码（优先选 ICLR/NeurIPS 的入门级论文） |

### 四、查漏补缺阶段（1 周）：解决实际编写中的问题



1. **高频问题攻克**：

* 调试技巧：打印张量形状（print (x.shape)）、查看梯度是否存在（print (param.grad)）

* 常见报错：维度不匹配（RuntimeError: size mismatch）、设备不一致（Expected object of device type cuda but got device type cpu）

1. **工具补充**：

* TensorBoard：简单使用（记录损失、准确率曲线），用 torch.utils.tensorboard.SummaryWriter

1. **实战检验**：

* 独立完成一个小任务：比如 “用 PyTorch 写一个线性回归模型，预测房价（用简化版房价数据集）”，从数据加载到模型训练全流程手写

> （注：文档部分内容可能由 AI 生成）